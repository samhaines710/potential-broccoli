name: Log Polygon Option Snapshots (CSV)

on:
  workflow_dispatch:
    inputs:
      duration_min:
        description: "Run duration in minutes (RTH ~ 390)."
        required: false
        default: "420"
      poll_seconds:
        description: "Polling interval seconds."
        required: false
        default: "15"
      near_atm_pct:
        description: "ATM band (e.g., 0.05 = 5%)."
        required: false
        default: "0.05"
      max_expiries:
        description: "Nearest expiries to keep."
        required: false
        default: "4"
  schedule:
    - cron: "30 14 * * 1-5"  # 14:30 UTC ≈ US RTH open, Mon–Fri

permissions:
  contents: read
  id-token: write
  actions: read

env:
  OUT_DIR: polygon_live_csv
  AWS_REGION: ${{ secrets.AWS_REGION }}
  AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}
  S3_SNAPSHOT_PREFIX: ${{ secrets.S3_SNAPSHOT_PREFIX }}

jobs:
  log-snapshots:
    runs-on: ubuntu-latest
    timeout-minutes: 480

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Assert POLYGON_API_KEY present
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${POLYGON_API_KEY:-}" ]; then
            echo "::error::POLYGON_API_KEY secret is missing."
            exit 1
          fi
          echo "OK: POLYGON_API_KEY present (hidden)."

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install runtime deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install requests

      - name: Verify logger exists
        run: |
          set -euo pipefail
          test -s "log_polygon_option_snapshots_csv.py" || {
            echo "::error::log_polygon_option_snapshots_csv.py not found at repo root."
            exit 1
          }

      - name: Prepare output dir
        run: |
          set -euo pipefail
          mkdir -p "${OUT_DIR}"

      - name: Run live logger loop
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          DURATION_MIN="${{ github.event.inputs.duration_min || '420' }}"
          POLL_SECONDS="${{ github.event.inputs.poll_seconds || '15' }}"
          NEAR_ATM_PCT="${{ github.event.inputs.near_atm_pct || '0.05' }}"
          MAX_EXPIRIES="${{ github.event.inputs.max_expiries || '4' }}"

          echo "Runner will poll for ${DURATION_MIN} minutes; poll=${POLL_SECONDS}s; atm=${NEAR_ATM_PCT}; expiries=${MAX_EXPIRIES}"
          END_TS=$(( $(date +%s) + DURATION_MIN*60 ))
          while [ "$(date +%s)" -lt "${END_TS}" ]; do
            python "log_polygon_option_snapshots_csv.py" \
              --out "${OUT_DIR}" \
              --poll "${POLL_SECONDS}" \
              --atm "${NEAR_ATM_PCT}" \
              --exp "${MAX_EXPIRIES}" || true
            sleep 2
          done

      - name: Sanity check: sample rows & zero/NaN scan
        run: |
          set -euo pipefail
          NEWEST="$(ls -1t "${OUT_DIR}"/*/*.csv 2>/dev/null | head -n1 || true)"
          if [ -z "${NEWEST}" ] || [ ! -f "${NEWEST}" ]; then
            echo "::error::No CSVs found under ${OUT_DIR}/"
            exit 1
          fi

          echo "Newest CSV: ${NEWEST}"
          echo "---- HEAD (first 15 rows) ----"
          head -n 15 "${NEWEST}"

          echo "---- BASIC STATS (awk) ----"
          awk -F, '
            BEGIN{
              iv_zero=delta_zero=gamma_zero=theta_zero=vega_zero=rho_zero=0;
              iv_empty=delta_empty=gamma_empty=theta_empty=vega_empty=rho_empty=0;
              rows=0
            }
            NR==1{next}
            {
              rows++;
              if($13=="" || $13=="NA" || $13=="NaN") iv_empty++;
              if($14=="" || $14=="NA" || $14=="NaN") delta_empty++;
              if($15=="" || $15=="NA" || $15=="NaN") gamma_empty++;
              if($16=="" || $16=="NA" || $16=="NaN") theta_empty++;
              if($17=="" || $17=="NA" || $17=="NaN") vega_empty++;
              if($18=="" || $18=="NA" || $18=="NaN") rho_empty++;

              if($13=="0" || $13=="0.0") iv_zero++;
              if($14=="0" || $14=="0.0") delta_zero++;
              if($15=="0" || $15=="0.0") gamma_zero++;
              if($16=="0" || $16=="0.0") theta_zero++;
              if($17=="0" || $17=="0.0") vega_zero++;
              if($18=="0" || $18=="0.0") rho_zero++;
            }
            END{
              if(rows==0){
                print "::error::CSV has header only; no data rows."; exit 2
              }
              printf("rows=%d\n", rows);
              printf("iv_empty=%d, delta_empty=%d, gamma_empty=%d, theta_empty=%d, vega_empty=%d, rho_empty=%d\n",
                     iv_empty, delta_empty, gamma_empty, theta_empty, vega_empty, rho_empty);
              printf("iv_zero=%d,  delta_zero=%d,  gamma_zero=%d,  theta_zero=%d,  vega_zero=%d,  rho_zero=%d\n",
                     iv_zero, delta_zero, gamma_zero, theta_zero, vega_zero, rho_zero);

              bad = iv_empty+delta_empty+gamma_empty+theta_empty+vega_empty+rho_empty \
                    + iv_zero+delta_zero+gamma_zero+theta_zero+vega_zero+rho_zero
              total_checks = rows * 6.0
              rate = bad / total_checks
              printf("bad_field_rate=%.4f\n", rate);

              thresh = 0.05;
              if(rate > thresh){
                printf("::error::Too many empty/zero IV/Greeks fields (%.2f%% > %.2f%% threshold).\n", rate*100.0, thresh*100.0);
                exit 3
              } else {
                printf("OK: empty/zero IV/Greeks fields within threshold (%.2f%% <= 5%%).\n", rate*100.0);
              }
            }
          ' "${NEWEST}"

          echo "---- SAMPLE (random-ish 10) ----"
          LINES=$(wc -l < "${NEWEST}")
          if [ "${LINES}" -gt 11 ]; then
            head -n 1 "${NEWEST}"
            STEP=$(( (LINES-1)/10 )); [ $STEP -lt 1 ] && STEP=1
            i=2; c=0
            while [ $c -lt 10 ] && [ $i -le $LINES ]; do
              sed -n "${i}p" "${NEWEST}"
              i=$(( i + STEP )); c=$(( c + 1 ))
            done
          else
            tail -n +2 "${NEWEST}"
          fi

      - name: Upload CSVs as artifact (daily)
        uses: actions/upload-artifact@v4
        with:
          name: polygon_live_csv_${{ github.run_id }}
          path: ${{ env.OUT_DIR }}/
          retention-days: 7
          if-no-files-found: warn

      - name: (Optional) Configure AWS (OIDC)
        if: ${{ env.AWS_ROLE_ARN && env.S3_SNAPSHOT_PREFIX }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION || 'us-east-1' }}

      - name: (Optional) Sync CSVs to S3
        if: ${{ env.AWS_ROLE_ARN && env.S3_SNAPSHOT_PREFIX }}
        run: |
          set -euo pipefail
          echo "Syncing ${OUT_DIR} -> ${S3_SNAPSHOT_PREFIX}"
          aws s3 sync "${OUT_DIR}/" "${S3_SNAPSHOT_PREFIX}/" --only-show-errors
