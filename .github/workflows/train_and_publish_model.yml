name: Generate Data, Train & Publish Model

on:
  push:
    paths:
      - "Grond-main 2/**"
      - ".github/workflows/train_and_publish_model.yml"
  workflow_dispatch:

jobs:
  train-and-upload:
    name: Train & Upload to S3
    runs-on: ubuntu-latest
    environment: CI
    env:
      # Make project package-resolvable (space-safe by quoting)
      PYTHONPATH: "${{ github.workspace }}/Grond-main 2"
      AWS_DEFAULT_REGION: ${{ vars.AWS_DEFAULT_REGION }}
      ML_MODEL_PATH: ${{ vars.ML_MODEL_PATH }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: "${{ runner.os }}-pip-${{ hashFiles('Grond-main 2/requirements.txt') }}"
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        working-directory: "Grond-main 2"
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r requirements.txt boto3

      - name: Ensure local utils is a package
        working-directory: "Grond-main 2"
        run: |
          python - <<'PY'
import pathlib
p = pathlib.Path("utils/__init__.py")
p.parent.mkdir(parents=True, exist_ok=True)
if not p.exists():
    p.write_text("# make utils a package\n")
print("utils package at:", p.resolve())
PY

      - name: Prepare training data
        working-directory: "Grond-main 2"
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          mkdir -p data
          python prepare_training_data.py
          test -s data/movement_training_data.csv

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_DEFAULT_REGION }}

      - name: Install AWS CLI
        run: |
          python -m pip install --upgrade awscli
          aws --version

      - name: Derive S3 URIs
        id: s3vars
        shell: bash
        run: |
          set -euo pipefail
          uri="${ML_MODEL_PATH}"
          if [[ "$uri" != s3://* ]]; then
            echo "ML_MODEL_PATH must be an s3:// URI; got: $uri" >&2
            exit 1
          fi
          bucket="${uri#s3://}"; bucket="${bucket%%/*}"
          {
            echo "bucket=$bucket"
            echo "model_uri=$uri"
            echo "csv_uri=s3://$bucket/data/movement_training_data.csv"
          } >> "$GITHUB_OUTPUT"

      - name: Upload training CSV to S3
        working-directory: "Grond-main 2"
        run: |
          aws s3 cp data/movement_training_data.csv "${{ steps.s3vars.outputs.csv_uri }}" --only-show-errors

      - name: Train model pipeline
        working-directory: "Grond-main 2"
        run: |
          mkdir -p models
          python train_ml_classifier.py \
            --train-csv   data/movement_training_data.csv \
            --label-col   movement_type \
            --model-dir   models \
            --model-filename xgb_classifier.pipeline.joblib
          test -s models/xgb_classifier.pipeline.joblib

      - name: Upload model artifact to S3
        working-directory: "Grond-main 2"
        run: |
          aws s3 cp models/xgb_classifier.pipeline.joblib "${{ steps.s3vars.outputs.model_uri }}" --only-show-errors

      - name: Upload artifacts to GitHub
        uses: actions/upload-artifact@v4
        with:
          name: model-and-data
          path: |
            Grond-main 2/data/movement_training_data.csv
            Grond-main 2/models/xgb_classifier.pipeline.joblib
          if-no-files-found: error
